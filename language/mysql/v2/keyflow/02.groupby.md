## [group by](https://github.com/alice52/java-ocean/issues/154)

```sql
create table t_group_by (
  id int unsigned auto_increment primary key,
  i1 int unsigned default '0'  null,
  c1 char(11)      default ''   null,
  e1 enum ('北京', '上海', '广州', '深圳', '天津', '杭州', '成都', '重庆', '苏州', '南京', '洽尔滨', '沈阳', '长春', '厦门', '福州', '南昌', '泉州', '德清', '长沙', '武汉') default '北京' null,
  d1 decimal(10, 2) null
) charset = utf8;
create index idx_e1_i1 on t_group_by (e1, i1);

INSERT INTO t_group_by (id, i1, c1, e1, d1) VALUES (1, 11, '11 测试char', '深圳', 156.15);
INSERT INTO t_group_by (id, i1, c1, e1, d1) VALUES (2, 12, '12 测试char', '深圳', 165.54);
INSERT INTO t_group_by (id, i1, c1, e1, d1) VALUES (3, 13, '13 测试char', '深圳', 156.40);
INSERT INTO t_group_by (id, i1, c1, e1, d1) VALUES (4, 14, '14 测试char', '深圳', 65.45);
INSERT INTO t_group_by (id, i1, c1, e1, d1) VALUES (5, 15, '15 测试char', '深圳', 45.70);
INSERT INTO t_group_by (id, i1, c1, e1, d1) VALUES (6, 16, '16 测试char', '成都', 1564.40);
INSERT INTO t_group_by (id, i1, c1, e1, d1) VALUES (7, 17, '17 测试char', '南京', 15.15);
INSERT INTO t_group_by (id, i1, c1, e1, d1) VALUES (8, 18, '18 测试char', '南京', 156.45);
INSERT INTO t_group_by (id, i1, c1, e1, d1) VALUES (9, 19, '19 测试char', '南京', 65.50);
INSERT INTO t_group_by (id, i1, c1, e1, d1) VALUES (10, 20, '20 测试char', '德清', 65.55);
```

### 简介: `组+能取的字段+聚合+过滤`

1. 分组

   - group by 后面有多个字段时则多个字段完全相同则为一组

2. 能取的字段

   - 通常, 选定的列必须包含在 group by 中: 如果 group by a, 有两列数据 a 列相同, 那么 select 其他字段是非法的, 因为他的值是不确定的.
   - 如果 group-by 的是主键列, 或者是可以唯一标识一条记录的[即 group-by 之前和之后的 row-count 一样]: 对于有唯一性约束的字段, 也可以不用在 group by 中把 select 中的字段全部列出来
   - 5.7 之后可以通过参数去控制是可以获取*非法字段*: `only_full_group_by`

   ```sql
   select @@sql_mode;
   set @@sql_mode = sys.list_drop(@@sql_mode, 'only_full_group_by');
   set @@sql_mode = sys.list_add(@@sql_mode, 'only_full_group_by');
   ```

3. 聚合

   - 如果在不包含 group by 子句的语句中使用组合函数, 就等效于对所有行进行分组
   - 聚合函数

     1. 方差和标准差函数会对数值参数返回 double 值
     2. sum()和 avg() 对精确值参数[integer 或 decimal]返回 decimal 值, 而对近似值参数[float 或 double]返回 double 值
     3. 时间类型的参数对 sum()和 avg()无效: 它们会把时间类型的值转换成数字, 丢弃第一个非数字字符后的所有信息

     ```sql
     min/max/sum/avg([distinct] expr) -- distinct 则用于返回 expr 的不同值的平均值 & 如果没有匹配的行, avg()返回 null
     count([distinct] expr, [expr...]) -- null 值不会被 count 统计
     group_concat([distinct] expr [,expr ...]
               [order by {unsigned_integer | col_name | expr} [asc | desc] [,col_name ...]]
               [separator str_val])  -- 分组后的拼装
     json_arrayagg(col or expr)      -- 将结果集聚合为单个json数组
     json_objectagg(key,value)       -- 返回包含键值对的json对象, 键名称为null
     ```

4. 过滤: having

   - having 子句
     1. group by 的字段
     2. 聚合函数
   - 功能:
     1. 是否存在缺失的编号: `having count(*) <> max(id) - min(id) + 1`
     2. 众数:
     3. 中位数: 非等值自连接 + sum-case-count
     4. 是否存在列值为 null: count

### 执行流程{实现}

1.  [命中索引]使用[松散索引扫描]实现 group by: 自带去重功能{完全 match distinct}

    - 定义:

      1. 从存储引擎读取分组记录时会**跳着**读
      2. 读取 **`分组前缀`** 后, 直接通过分组前缀定位到分组中符合 where 条件的第一条或最后一条记录, 而**不需要读取分组的所有记录**
      3. 然后就接着读取下一个分组的分组前缀, 减少 select 语句执行过程中需要读取的记录数
      4. 因此`一般`比紧凑索引扫描更快

      ![avatar](/static/image/mysql/key-groupby-loose-instance.png)

    - explain 标识: `extra: Using index for group-by`

      ![avatar](/static/image/mysql/key-groupby-loose.png)

    - 条件: `t1(c1,c2,c3,c4)-idx(c1,c2,c3)`

      1. 仅限于单表查询
      2. group by 字段必须满足索引的最左匹配原则: **where 不参与前缀**
         - 满足的: `distinct c1, c2` || `where c2 > const group by c1, c2`
         - 不满足的: `where c2='a' group by c1, c3 || where c1='a' group by c2, c3`
      3. 只能是其中一组 `max / min` || `count(distinct) / sum(distinct) / avg(distinct)`
         - 原因: 两组的分组前缀逻辑不同
         - min / max 用 `group by 字段值`作为分组前缀
         - count(distinct)/sum(distinct)/avg(distinct) 用 `group by 字段值 + 聚合函数中的字段值`作为分组前缀
      4. 使用到的索引必须是全字段索引: 不能是前缀索引

    - 执行流程: min
      ```sql
      select e1, min(i1) from t_group_by group by e1
      ```
      1. 词法分析 & 语法分析阶段: `min(i1) 被解析为 Item_sum_min 类`
      2. 查询准备阶段: 关联最小值字段为
      3. 执行阶段
         - 读取分组前缀: min/max 分组前缀为 group by 的字段
         - 根据分组前缀读取分组最小值: 使用前缀限定索引扫描访问, 获取最小值; 不会读所有值(b+tree)

2.  [命中索引]使用紧凑索引扫描实现 group by: _去重则需要临时表{会被优化成不是临时表多数}_

    - 定义:

      1. 以索引**范围扫描或全索引扫描**方式, 按顺序一条一条读取记录, 不会跳过中间的某条记录
      2. 读取所有满足条件的索引键, 然后再根据读取恶的数据来完成 GROUP BY 操作得到相应结果

         ![avatar](/static/image/mysql/key-groupby-tight-instance.png)

    - explain 标识: 没有 Using index for group-by 且没有 temporary

      ![avatar](/static/image/mysql/key-groupby-tight.jpg)

    - 条件
      1. **group by 字段包含在索引中**
      2. 满足索引最左匹配原则: where 参与前缀计算
    - 执行流程: avg{对字段值进行累加(sum), 对次数计数(count), 最终分组结束会通过 sum/count 求的 avg}

      ```sql
      -- 紧凑索引扫描
      select e1, avg(i1) as t from t_group_by where d1>5452415 group by e1;
      -- 紧凑索引扫描
      select i1 as t from t_group_by where e1='深圳' group by i1;

      -- 临时表
      select i1 as t from t_group_by where e1>'深圳' group by i1;
      ```

      1. 词法分析 & 语法分析阶段: `avg(i1) 被解析为 Item_sum_avg 类`
      2. 查询准备阶段: 关联最小值字段为
      3. 执行阶段
         - server 层从存储引擎读取到一条记录, 判断记录是否符合 where 条件
         - 记录不符合 where 条件, 继续读取下一条记录
         - 记录符合 where 条件, 进行聚合函数逻辑处理
           1. 如果当前记录的分组前缀和上一条记录的分组前缀不一样, 说明需要结束上一个分组, 并开启新分组
              - 结束上一个分组: 通过 sum / count 计算得到分组平均值, 把分组前缀及分组平均值发送给客户端
              - 开启新分组: Item_sum_avg 类的实例属性 sum, count 清零, 当前记录的 e1 字段值作为新分组前缀, 然后新分组进行分组求和(sum 加上 i1 字段值), 分组计数(count 加 1)
           2. 如果当前记录的分组前缀和上一条记录的分组前缀一样, 说明还是同一个分组, 只需要进行分组求和、分组计数, 不需要计算平均值

    - 执行流程 2: 不需要存储中间值, 可以直接得到结果

      ```sql
      select id%100 as m, count(*) as c from t1 group by m;
      alter table t1 add column z int generated always as(id % 100), add index(z);
      select z, count(*) as c from t1 group by z;
      ```

      ![avatar](/static/image/mysql/key-groupby-tight-flow.png)

      1. 只需要从左到右, 顺序扫描, 依次累加
      2. 当碰到第一个 1 的时候, 已经知道累积了 X 个 0, 结果集里的第一行就是 (0,X);
      3. 当碰到第一个 2 的时候, 已经知道累积了 Y 个 1, 结果集里的第二行就是 (1,Y);
      4. 按照这个逻辑执行的话, 扫描到整个输入的数据结束, 就可以拿到 group by 的结果, 不需要临时表, 也不需要再额外排序

3.  使用临时表实现 group by

    - 定义:

      1. 通过索引扫描并不能直接得到 group by 的结果
      2. 则需要创建临时表存放中间结果
      3. 8.0 之前会再次对 group by 之后的结果进行排序操作

    - explain 标识: Using temporary; _Using filesort_

      ![avatar](/static/image/mysql/key-groupby-temp.jpg)

    - 执行流程

      ```sql
      create table t1(id int primary key, a int, b int, index(a));
      -- type: index, extra: Using index{覆盖索引不回表}; Using temporary{使用临时表}; Using filesort{需排序}
      select id%10 as m, count(*) as c from t1 group by m;
      ```

      1. 判断根据索引是否可以直接得到结果, 可以的话就直接走索引, 不会产生临时表
      2. 不能的话会先得到需要的数据: 可以索引等条件获取
      3. 创建内存临时表, 表里有两个字段 m 和 c, 主键是 m
      4. 扫描表 t1 的索引 a, 依次取出叶子节点上的 id 值, 计算 id%10 的结果, 记为 x
         - 如果临时表中没有主键为 x 的行, 就插入一个记录 (x,1);
         - 如果表中有主键为 x 的行, 就将 x 这一行的 c 值加 1
      5. 遍历完成后, 再根据字段 m 做排序{如果 sort_buffer 不够则会使用文件排序}, 得到结果集返回给客户端
      6. 过程中如果内存临时表满了, 就会把内存临时表转成磁盘临时表{磁盘临时表就会变的有序的(innodb 的 b+tree)}

      ![avatar](/static/image/mysql/key-groupby-temp-flow.png)

#### 效率问题

1. 一般 `松散索引 优于 紧凑索引`

   - 在没有 where 子句{全索引扫描}, 松散索引扫描需要读取的键值数量与分组的组数量一样多{比实际存在的键值数目要少很多}
   - 在 where 子句{含范围或等值}, 松散索引扫描查找满足范围条件的每个组的第 1 个关键字, **并且再次读取尽可能最少数量的关键字**

2. 松散索引扫描成本更高: 很少的情况下

   - 紧凑索引是按照顺序读取记录{first key 是常量}, 之后判断是否满 where 条件{比如 d1}, 符合则进行相关的聚合处理
   - 松散索引是对于每个分组读取两次数据{也可能树索引}: 获取分组前缀 + 读取改分组前缀下的第一条或最后一条
   - 因此, 如果分组内没有很多记录{极端下只有一条记录}, 能跳过的就很小, 可能导致每个分组读取两次{数据}的成本高于跳过的{索引扫面的}成本, 从而导致代价高于紧凑索引
   - 原因总结: 因为分组中记录数量少时, **两次读取存储引擎数据增加的成本超过了跳着读取索引记录节省的成本**, 当然如果读取的都是索引, 那么一定是松散代价小

3. mysql 的选择

   - 松散索引成本小于紧凑索引时, 会直接使用松散索引
   - 松散索引成本大于紧凑索引时: 对 distinct 做了针对性优化

     1. min/max 会直接选择紧凑索引
     2. count(distinct)/sum(distinct)/avg(distinct): _此时会使用紧凑索引_, 但是去重又需要临时表, 开销有变的可能大于松散索引
     3. `2` 的情况下, mysql 会直接将其优化为使用 `Using index for group-by (scanning)`: 顺序扫描数据 + 利用松散索引的去重
     4. **对于包含 distinct 关键字的聚合函数, 就会用顺序读取记录代替跳着读取记录, 并且在顺序读取记录的过程中完成记录去重**

     ![avatar](/static/image/mysql/key-groupby-ltscan.png)

### 临时表

1. 为什么会使用临时表: `仅当前连接可见, 连接断开后自动释放`

   - 如果语句执行过程可以一边读数据, 一边直接得到结果, 是不需要额外内存的, 否则就需要额外的内存, 来保存中间结果
   - **join_buffer 是无序数组**, `sort_buffer 是有序数组`, **临时表是二维表结构**

   - 分类

     1. [优先]内存临时表: {tmp_table_size:16M}, 默认采用的是 memory 引擎
     2. 磁盘临时表: 默认采用 innodb 引擎{5.7.6 之后}

   - 查看执行过程中使用的临时表数量

     ```sql
     -- 磁盘临时表: created_tmp_disk_tables
     -- 内存临时表: created_tmp_tables
     show global status like 'created_tmp%';
     ```

   - **如果执行逻辑需要用到二维表特性, 就会优先考虑使用临时表**

     1. 比如例子中 union 需要用到唯一索引约束
     2. 比如例子中 group by 还需要用到另外一个字段来存累积计数

   - 产生临时表的常见情景

     1. from 中的子查询
     2. union: 去重用到
     3. group by 没有索引可以使用: 存放中间结果
     4. order by 和 group by 的子句不一样时: `group by store_id order by count(store_id)`
     5. order by rand(): 临时表+排序
     6. distinct & order by
        - distinct 没有索引的字段: 只会产生临时表
        - order by 字段没有索引, 则只会排序
        - distinct + order by: 不同的字段即使有索引也会临时表+排序
     7. 表连接中 order by 的列不是驱动表中的
     8. 子查询或者 semi-join 时创建的表

### optimize

1. 去掉临时表{加索引}: 使用紧凑索引扫描或者松散索引扫面

   - 直接加索引
   - generated column 机制: 设计计算的

2. [不适合间索引+临时表会放很多数据]直接排序: `直接使用排序算法后计算groupby结果`

   ```sql
   -- type: index, extra: using filesort{排序}, using index{覆盖索引}
   select sql_big_result id%100 as m, count(*) as c from t1 group by m;
   ```

   - 正常时先放到内存临时表, 插入一部分数据后, 发现内存临时表不够用了再转成磁盘临时表{不友好}
   - sql_big_result: 按数组形式使用*磁盘临时表*{优先使用 sort_buffer}
     1. sql_big_result 告诉 mysql 的分组语句必须使用磁盘临时表(默认使用内存临时表)
     2. 优化器针对 sql_big_result 从节省磁盘空间的角度对数据的存储的方式做了优化: 采用数组
   - 执行流程

     1. 初始化 sort_buffer, 确定放入一个整型字段, 记为 m
     2. 扫描表 t1 的索引 a, 依次取出里面的 id 值, 将 id%100 的值存入 sort_buffer 中
     3. 扫描完成后, 对 sort_buffer 的字段 m 做排序(如果 sort_buffer 内存不够用, 就会利用磁盘临时文件辅助排序)
     4. 排序完成后, 就得到了一个有序数组
     5. 根据有序数组则可以计算得到最终的结果

     ![avatar](/static/image/mysql/key-groupby-opt-big-result.png)

3. 5.7 及之前不需要对结果集排序则写明 `order by null`
4. [多表多分组] group by 多个字段但是表取的数据是 1:1 的关系, 1:n 的表被聚合

   - 此时可以优化成只通过主表的 Id 分组 + 修改 sql_mode{驱除 only_full_group_by}

5. [多表多分组] 其中主表的 group by 是常量(const), 则 sql 执行时会被优化为一个 groupby

### practice

1. [优化案例](https://github.com/Alice52/java-ocean/issues/154#issuecomment-808638264)
2. group by 多张表的多个字段

   ```sql
   explain
   select
       ms.gm_eid,
       jud.position_id,
       avg(jud.total_score),
       -- 50w 的数据下, 每个聚合函数会消耗 0.1-0.2s
       count(jud.id)
   from  all_star_judgement jud
   -- 如果 jud 作为左表 left join 时, 则 ms.gm_eid 明确且 ms.gm_eid 值确实存在且 gm_eid 都存在[索引可以名中到这一级], 就不会产生临时表[因为此时 jud 作为左表]
   -- 如果 ms  作为左表 left join 时, 则 jud.position_id 明确且 ms.position_id 值确实存在且 gm_eid 都存在[索引可以名中到这一级], 不会产生临时表[因为 ms 作为左表]
   -- 如果 innner join 时, 则 jud.position_id 或者 ms.gm_eid 明确且存在, 且能命中到到这一级, 就不会产生临时表[因为可以使用另一个作为主表]
   join mcd_store ms on ms.id = jud.store_id and ms.is_deleted=0 and ms.store_ops_status='a'
   where jud.is_deleted=0
       and ms.region_name='jjj&n'
       and market_id=154
       and position_id=5
   group by jud.position_id, ms.gm_eid
   order by null;
   ```

### 小结

1. group-by 和 order-by 的关系:
   - 5.7 及之前 mysql 会对 group by 的字段进行排序: `排序后再分组是一个很快速的方式`
   - 8.0 则取消了对结果集的分组
2. 如果对 group by 语句的结果没有排序要求, 要在语句后面加 order by null
3. 尽量让 group by 过程用上表的索引, 使用松散索引扫描或者使用紧凑索引扫描
4. 如果 group by 需要统计的数据量不大, 尽量只使用内存临时表, 也可以通过适当调大 tmp_table_size 参数, 来避免用到磁盘临时表
5. 如果数据量实在太大, 使用 SQL_BIG_RESULT 这个提示, 来告诉优化器直接使用排序算法得到 group by 的结果

### issue

1. `select i1 as t from t_group_by where e1='深圳' group by i1;` 为什么不能使用 loose index scan

## reference

1. [group by - 索引扫描 8.0](https://dev.mysql.com/doc/refman/8.0/en/group-by-optimization.html)
2. [group by - 索引扫描 5.7](https://mp.weixin.qq.com/s/oJ7_8Bfumw3yAUEqluK2Pg)
3. [group by - 索引扫描 summary](https://www.cnblogs.com/bonelee/p/6359250.html)
4. [group by - 实现原理](https://time.geekbang.org/column/article/80477)
5. [group by - 8.0 不在默认排序](https://dev.mysql.com/blog-archive/removal-of-implicit-and-explicit-sorting-for-group-by/)
6. [group by - aggregate 函数](https://dev.mysql.com/doc/refman/5.7/en/aggregate-functions.html)
7. [group by - having](https://mp.weixin.qq.com/s/46woqFA6VscqairFsGWXcQ)
8. [group by - select](https://blog.csdn.net/qq_24432315/article/details/108162808)
9. [group by - 临时表](https://www.jb51.net/article/147261.htm)
10. [group by](https://github.com/alice52/java-ocean/issues/154)
