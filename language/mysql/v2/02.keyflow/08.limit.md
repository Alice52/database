### limit 大数

1. 原因

   - limit 100000, 20 的意思扫描满足条件的 100020 行(回表的){**可以查看 sql 的读取数据页的数量**}, 扔掉前面的 100000 行, 返回最后的 20 行
   - 大量的时间都花费在随机 io[回表]上: 尤其查询偏移大于**10 万**以后查询时间急剧增加

   ```sql
   -- limit 大数: 慢 & 污染buffer pool
   -- 两次验证之间要清空bp: 重启服务
   select index_name,count(*)
   from information_schema.innodb_buffer_page
   where index_name in('val','primary') and table_name like '%test%'
   group by index_name;
   ```

2. 解决方案: `覆盖索引-数据id` **利用延迟关联或者子查询优化超多分页场景**

   - limit 默认会加载所有数据并过滤掉前面的 10w 行, 只取 20 行: 不是很好
   - solution01: 使用条件过滤{将 limit 转换为过滤条件}
   - solution02: **利用覆盖索引, 省去回表的耗时: 写子查询去确定边界**
   - 也可以在业务允许的情况下, 限制页数

3. sample 1

   ```sql
   -- 慢 & 加载了很多热点不是很高的数据页到buffer pool, 会造成buffer pool的污染, 占用buffer pool的空间
   select id, title, ico, create_time, create_user
   from article_copy1
   where `status` = '1'
   order by id des limit 100000, 10

   -- solution01: 将上一次的最大的id传递给前端
   select id, title, ico, create_time, create_user
   from article_copy1
   where `status` = '1' and id < 2155652
   order by id desc
   limit 10;

   select id, title, ico, create_time, create_user
   from article_copy1
   where `status` = '1' and id >= (select id from article_copy1  where `status` = '1' order by id desc limit 100000, 1)
   order by id desc
   limit 10


   select id, title, ico, create_time, create_user
   from article_copy1 c1
   join (select id from article_copy1  where `status` = '1' order by id desc limit 100000, 1) t on t.id=c1.id
   where `status` = '1'
   order by id desc
   limit 10
   ```

4. sample 2

   ```sql
   -- test table, val is common index
   mysql> desc test;
   +--------+---------------------+------+-----+---------+----------------+
   | Field  | Type                | Null | Key | Default | Extra          |
   +--------+---------------------+------+-----+---------+----------------+
   | id     | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment |
   | val    | int(10) unsigned    | NO   | MUL | 0       |                |
   | source | int(10) unsigned    | NO   |     | 0       |                |
   +--------+---------------------+------+-----+---------+----------------+
   3 rows in set (0.00 sec)

   -- origin: 会走 val 的索引, 但是最后 select * 包含 source 数据, 所以需要回表, 且要回表 300000 次
   -- 大量的回表且数据并不是最终想要的: 大量随机 I/O 在查询聚簇索引的数据
   mysql> select * from test where val=4 limit 300000, 5;
   +---------+-----+--------+
   | id      | val | source |
   +---------+-----+--------+
   | 3327622 |   4 |      4 |
   | 3327632 |   4 |      4 |
   | 3327642 |   4 |      4 |
   | 3327652 |   4 |      4 |
   | 3327662 |   4 |      4 |
   +---------+-----+--------+
   5 rows in set (15.98 sec)

   -- after: 先执行子查询获得id, 不会回表; 之后 inner join[命中id索引], 会根据索引过滤之后再 join; 之后 select * 会回表[5次]
   mysql> select * from test a
         inner join (select id from test where val=4 limit 300000,5) b on a.id=b.id;
   +---------+-----+--------+---------+
   | id      | val | source | id      |
   +---------+-----+--------+---------+
   | 3327622 |   4 |      4 | 3327622 |
   | 3327632 |   4 |      4 | 3327632 |
   | 3327642 |   4 |      4 | 3327642 |
   | 3327652 |   4 |      4 | 3327652 |
   | 3327662 |   4 |      4 | 3327662 |
   +---------+-----+--------+---------+
   5 rows in set (0.38 sec)
   ```

   - buffer pool: 里面存有最近访问过的数据页, 包括数据页和索引页: 分析两次比较需要清空 buffer pool
   - 清空 buffer pool: `[重启且关闭 innodb_buffer_pool_dump_at_shutdown/innodb_buffer_pool_load_at_startup]`

     ```sql
     mysql> select * from test where val=4 limit 300000,5;
     +---------+-----+--------+
     | id      | val | source |
     +---------+-----+--------+|
     | 3327622 |   4 |      4 |
     | 3327632 |   4 |      4 |
     | 3327642 |   4 |      4 |
     | 3327652 |   4 |      4 |
     | 3327662 |   4 |      4 |
     +---------+-----+--------+
     5 rows in set (26.19 sec)

     -- 加载了 4098 个数据页和 208 个索引页到 buffer pool
     mysql> select index_name,count(*) from information_schema.INNODB_BUFFER_PAGE
        where INDEX_NAME in('val','primary') and TABLE_NAME like '%test%' group by index_name;
     +------------+----------+
     | index_name | count(*) |
     +------------+----------+
     | PRIMARY    |     4098 |
     | val        |      208 |
     +------------+----------+
     2 rows in set (0.04 sec)

     mysql> select * from test a inner join (select id from test where val=4 limit 300000, 5) b on a.id=b.id;
     +---------+-----+--------+---------+
     | id      | val | source | id      |
     +---------+-----+--------+---------+
     | 3327622 |   4 |      4 | 3327622 |
     | 3327632 |   4 |      4 | 3327632 |
     | 3327642 |   4 |      4 | 3327642 |
     | 3327652 |   4 |      4 | 3327652 |
     | 3327662 |   4 |      4 | 3327662 |
     +---------+-----+--------+---------+
     5 rows in set (0.09 sec)

     -- 加载了 5 个数据页到和 390 个索引页到 buffer pool
     mysql> select index_name,count(*) from information_schema.INNODB_BUFFER_PAGE
        where INDEX_NAME in('val','primary') and TABLE_NAME like '%test%' group by index_name;
     +------------+----------+
     | index_name | count(*) |
     +------------+----------+
     | PRIMARY    |        5 |
     | val        |      390 |
     +------------+----------+
     2 rows in set (0.03 sec)
     ```

## reference

1. [优化-limit](https://blog.csdn.net/liuxl57805678/article/details/91377203)
2. [优化-limit](https://mp.weixin.qq.com/s?__biz=MzI5NTYwNDQxNA==&mid=2247493461&idx=2&sn=73b066634dd97041ee3e28b764cbeafe)
3. [优化-limt](https://mp.weixin.qq.com/s/1PcaYPKAshFz6D93BsCaDA)
4. [优化-limt](https://mp.weixin.qq.com/s?__biz=MzIyNDE1NTA4OQ==&mid=2651092451&idx=1&sn=e77444157e507016c496306cda06acac)
5. [优化-limt](https://mp.weixin.qq.com/s?__biz=MzA4NzQ0Njc4Ng==&mid=2247488017&idx=1&sn=29192559eefaf7eaf57bc27c441fed6f)
6. [orderby-limt](https://mp.weixin.qq.com/s/r1QC0UDkwtLUhPszr1tFpQ)
