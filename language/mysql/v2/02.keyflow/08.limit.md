### limit 大数

1. 原因

   - limit 100000, 20 的意思扫描满足条件的 100020 行(回表的){**可以查看 sql 的读取数据页的数量**}, 扔掉前面的 100000 行, 返回最后的 20 行
   - 大量的时间都花费在随机 io[回表]上: 尤其查询偏移大于**10 万**以后查询时间急剧增加

   ```sql
   -- limit 大数: 慢 & 污染buffer pool
   -- 两次验证之间要清空bp: 重启服务
   select index_name,count(*)
   from information_schema.innodb_buffer_page
   where index_name in('val','primary') and table_name like '%test%'
   group by index_name;
   ```

2. 解决方案: `覆盖索引-数据id` **利用延迟关联或者子查询优化超多分页场景**

   - limit 默认会加载所有数据并过滤掉前面的 10w 行, 只取 20 行: 不是很好
   - solution01: 使用条件过滤{将 limit 转换为过滤条件}
   - solution02: **利用覆盖索引, 省去回表的耗时: 写子查询去确定边界**
   - 也可以在业务允许的情况下, 限制页数

3. sample

   ```sql
   -- 慢 & 加载了很多热点不是很高的数据页到buffer pool, 会造成buffer pool的污染, 占用buffer pool的空间
   select id, title, ico, create_time, create_user
   from article_copy1
   where `status` = '1'
   order by id des limit 100000, 10

   -- solution01: 将上一次的最大的id传递给前端
   select id, title, ico, create_time, create_user
   from article_copy1
   where `status` = '1' and id < 2155652
   order by id desc
   limit 10;

   select id, title, ico, create_time, create_user
   from article_copy1
   where `status` = '1' and id >= (select id from article_copy1  where `status` = '1' order by id desc limit 100000, 1)
   order by id desc
   limit 10


   select id, title, ico, create_time, create_user
   from article_copy1 c1
   join (select id from article_copy1  where `status` = '1' order by id desc limit 100000, 1) t on t.id=c1.id
   where `status` = '1'
   order by id desc
   limit 10
   ```

## reference

1. [优化-limit](https://blog.csdn.net/liuxl57805678/article/details/91377203)
2. [优化-limit](https://mp.weixin.qq.com/s?__biz=MzI5NTYwNDQxNA==&mid=2247493461&idx=2&sn=73b066634dd97041ee3e28b764cbeafe)
3. [优化-limt](https://mp.weixin.qq.com/s/1PcaYPKAshFz6D93BsCaDA)
4. [优化-limt](https://mp.weixin.qq.com/s?__biz=MzIyNDE1NTA4OQ==&mid=2651092451&idx=1&sn=e77444157e507016c496306cda06acac)
5. [优化-limt](https://mp.weixin.qq.com/s?__biz=MzA4NzQ0Njc4Ng==&mid=2247488017&idx=1&sn=29192559eefaf7eaf57bc27c441fed6f)
